{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7b7f12ef",
      "metadata": {
        "id": "7b7f12ef"
      },
      "source": [
        "# Web Scraping e Fundamentos de HTML\n",
        "\n",
        "O **web scraping** √© uma t√©cnica de extra√ß√£o de informa√ß√µes de p√°ginas da web. Ele permite que voc√™ colete e processe dados automaticamente, utilizando Python e bibliotecas como **BeautifulSoup** e **Requests**.\n",
        "\n",
        "Neste notebook, vamos explorar:\n",
        "\n",
        "1. Fundamentos de HTML e estrutura de p√°ginas.\n",
        "2. Uso do BeautifulSoup para extra√ß√£o de dados.\n",
        "3. Extra√ß√£o de tabelas usando Pandas.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db92c6d5",
      "metadata": {
        "id": "db92c6d5"
      },
      "source": [
        "## O que √© Web Scraping?\n",
        "\n",
        "O web scraping √© amplamente utilizado para:\n",
        "- **Coleta de dados:** como pre√ßos de produtos, an√°lises de mercado, etc.\n",
        "- **Monitoramento de informa√ß√µes:** como atualiza√ß√µes de not√≠cias ou estat√≠sticas em tempo real.\n",
        "- **Agrega√ß√£o de conte√∫do:** consolidando informa√ß√µes de v√°rias fontes em um √∫nico lugar.\n",
        "\n",
        "Para realizar scraping, precisamos:\n",
        "1. Fazer uma **requisi√ß√£o HTTP** para acessar a p√°gina.\n",
        "2. **Analisar o conte√∫do HTML** retornado.\n",
        "3. **Identificar e extrair** os dados desejados.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21b81bca",
      "metadata": {
        "id": "21b81bca"
      },
      "source": [
        "## Fundamentos de HTML\n",
        "\n",
        "O HTML √© a base de todas as p√°ginas da web. Ele √© estruturado em uma √°rvore de documentos, com elementos hier√°rquicos como tags, atributos e conte√∫do.\n",
        "\n",
        "### Estrutura B√°sica do HTML\n",
        "```html\n",
        "<html>\n",
        "  <head>\n",
        "    <title>T√≠tulo da P√°gina</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <h1>Bem-vindo ao Web Scraping</h1>\n",
        "    <p>Este √© um par√°grafo com <a href=\"https://example.com\">um link</a>.</p>\n",
        "    <table>\n",
        "      <tr>\n",
        "        <th>Coluna 1</th>\n",
        "        <th>Coluna 2</th>\n",
        "      </tr>\n",
        "      <tr>\n",
        "        <td>Dado 1</td>\n",
        "        <td>Dado 2</td>\n",
        "      </tr>\n",
        "    </table>\n",
        "  </body>\n",
        "</html>\n",
        "```\n",
        "\n",
        "### Elementos Importantes\n",
        "1. **Tags:** Delimitam o in√≠cio e o fim de elementos (`<h1>`, `<p>`, `<table>`).\n",
        "2. **Atributos:** Adicionam informa√ß√µes extras √†s tags (`href`, `id`, `class`).\n",
        "3. **Conte√∫do:** O texto ou elementos contidos dentro das tags.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "490a1bab",
      "metadata": {
        "id": "490a1bab"
      },
      "source": [
        "## Ferramentas Necess√°rias\n",
        "\n",
        "Para realizar web scraping, utilizaremos:\n",
        "- **Requests:** Para fazer requisi√ß√µes HTTP.\n",
        "- **BeautifulSoup:** Para analisar e manipular o HTML.\n",
        "- **Pandas:** Para extrair tabelas de p√°ginas diretamente.\n",
        "\n",
        "Certifique-se de instalar as bibliotecas necess√°rias:\n",
        "```bash\n",
        "pip install requests beautifulsoup4 pandas\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0175681",
      "metadata": {
        "id": "d0175681"
      },
      "source": [
        "## Exemplo 1: Coletando Dados de uma P√°gina\n",
        "\n",
        "Vamos come√ßar com um exemplo simples: extrair links de uma p√°gina da web.\n",
        "\n",
        "```python\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da p√°gina para scraping\n",
        "url = 'https://en.wikipedia.org/wiki/IBM'\n",
        "\n",
        "# Fazendo a requisi√ß√£o HTTP\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "# Criando o objeto BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Extraindo todos os links (<a> tags)\n",
        "links = soup.find_all('a')\n",
        "\n",
        "print(\"Links encontrados:\")\n",
        "for link in links[:10]:  # Mostrando apenas os 10 primeiros\n",
        "    print(link.get('href'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f1ff7e",
      "metadata": {
        "id": "e4f1ff7e"
      },
      "source": [
        "## Exemplo 2: Extraindo Dados Estruturados\n",
        "\n",
        "Vamos agora extrair dados de tabelas em uma p√°gina da web e transform√°-los em um DataFrame usando Pandas.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# URL com tabelas\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'\n",
        "\n",
        "# Fazendo a requisi√ß√£o\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extraindo todas as tabelas da p√°gina\n",
        "tables = pd.read_html(response.text)\n",
        "\n",
        "# Exibindo a primeira tabela\n",
        "print(\"Primeira tabela encontrada:\")\n",
        "df = tables[0]\n",
        "print(df.head())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b059562",
      "metadata": {
        "id": "2b059562"
      },
      "source": [
        "## Boas Pr√°ticas de Web Scraping\n",
        "\n",
        "1. **Respeite os Termos de Uso:** Sempre verifique se o site permite scraping em seus termos de uso.\n",
        "2. **Use um `User-Agent`:** Adicione um cabe√ßalho `User-Agent` √† sua requisi√ß√£o para se identificar como um cliente leg√≠timo.\n",
        "3. **Evite Sobrecarga no Servidor:** N√£o envie muitas requisi√ß√µes em curtos per√≠odos de tempo.\n",
        "4. **Valide os Dados Extra√≠dos:** Sempre confira se os dados extra√≠dos est√£o corretos.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935a833a",
      "metadata": {
        "id": "935a833a"
      },
      "source": [
        "## Conclus√£o\n",
        "\n",
        "Neste notebook, exploramos os fundamentos de HTML e como usar Python para realizar web scraping com **BeautifulSoup** e **Pandas**. Agora voc√™ pode coletar e estruturar dados de p√°ginas da web para an√°lise! üöÄ\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "- Experimente extrair dados de diferentes sites.\n",
        "- Combine os dados extra√≠dos com an√°lises avan√ßadas usando bibliotecas como Matplotlib ou Scikit-learn.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}